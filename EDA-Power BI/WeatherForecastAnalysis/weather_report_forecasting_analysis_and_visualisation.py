# -*- coding: utf-8 -*-
"""Weather report forecasting Analysis and Visualisation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11VllfCaLzkZLeJg1bonb_vRmRgV8eS1L

## **Weather Report Forecasting Analysis**

**Weather prediction is one of the most certainly required information in all over the regions
It involves collecting global meteorological surface and upper-air observations, preparing global surface and upper air pressure, temperature, moisture, and wind analyses at frequent time intervals based upon these observations we predict some data for upcoming days weather conditions**

## **Project Description:**

This data contains day wise weather attributes from 2022 to July 2033 (predicted data)

**Columns are as follows :**
* Date
* Average temperature (°F)
* Average humidity (%)
* Average dewpoint (°F)
* Average barometer (in)
* Average windspeed (mph)
* Average gust speed (mph)
* Average direction (°degree)
* Rainfall for month (in)
* Rainfall for year (in)
* Maximum rain per minute
* Maximum temperature (°F)
* Minimum temperature (°F)
* Maximum humidity (%)
* Minimum humidity (%)
* Maximum pressure
* Minimum pressure
* Maximum wind speed (mph)
* Maximum gust speed (mph)
* Maximum heat index (°F)

## **Step1: Data Collection**
The data set for this problem was provided by [HiCounselor](https://hicounselor.com/)

The use case pipeline build-up is started with imports of some basic libraries that are needed throughout the case especially for **Pre-Processing**. This includes Pandas and Numpy for data handling and processing.
"""

import numpy as np
import pandas as pd
pd.set_option('max_rows', None)
pd.set_option('max_columns', 100)

#Loading the data set
from google.colab import files
uploaded = files.upload()

df = pd.read_csv('weather_dataset.csv', encoding='cp1252')

"""## **Step2: Pre-Processing the Data**

* Subtask 1: Fix a few labels in the given data set

* Subtask 2: Removal of duplicate Columns

* Subtask 3: Correct years for given data set 

* Subtask 4 : Remove duplicate rows if any

"""

df.head()

df.info()

"""#### **Sub task1: Fixing labels in the dataset**

###### **By looking at the dataset, it is evident that the names of the column needs to be fixed.**

* Initially will remove all the white spaces at both the ends of the column name 

* Will convert the names into lower case for better readibility and consistency

* Will remove the brackets as the information of the units is not required for for analysing.

* Will remove the space between words of the columns and replace it with '_' for better readability

**Formating the column names**
"""

df.columns =  [col.split("(")[0].strip().replace(" ", "_").lower() for col in df]

df.head()

"""*There could be a possibility that we have -0 as miss print, which should be modified*"""



"""**The column names have been formated**

###### **Checking the non standard missing values**

* This will help us in identifying the issue in the entire dataset before the conversion of data types
"""

#Non Standard missing values</h3>
from collections import Counter

for col in df.columns:
    print(f'Column -- {col}')
    print(f'=========================')
    error_rows = []
    for row in df[col]:    
        try:
            float(row)
        except:
            error_rows.append(row)        
    print(f'{Counter(error_rows)}')

"""**There are a lot of non standard missing values which will be taken care of**

* The entire dataset is of the format '...'. Will remove `''` this and then convert it into their relevant datatypes. 

"""

for column in df.columns:
  values = []
  for i in df[column]:
    values.append(str(i).replace("'", "").strip())
  df[column] = values

df.head()

"""
#### **All the columns have a datatype `Object`, will convert into their relevant datat types**"""

df.date1 = pd.to_datetime(df.date1, errors = 'coerce')
df.date= pd.to_datetime(df.date, errors = 'coerce')

for col in df.columns:
  if col not in ('date', 'date1'):
    df[col] = pd.to_numeric(df[col], errors = 'coerce')

"""**All the data types have been changed**

**Let's now check the null values**
"""

df.isnull().sum()

"""*There are 2 missing values in the `date` column. Will treat it later*

###### **Sub Task2: Removing extra/duplicate columns/rows**

* Will check if the two `date` columns are identical and will drop one of them if the result is true. 

* Also, `month` and `diff_pressure`are not required for analysis as they are just calculated columns from the dataset

* Will also check if there are any duplicated rows in the dataset and drop them accordingly

**Will remove the unwamted columns**
"""

#Will check if the 2 dates column are identical
df.date.equals(df.date1)

"""*Both the date columns are identical, hence will drop one of them*"""

df.drop(['date1', 'month', 'diff_pressure'], axis =1, inplace = True)

"""**Will remove the duplicated rows**"""

df.duplicated().sum()

"""*There is only 1 duplicate row. hence will drop it*"""

df.drop_duplicates(keep = 'last', inplace = True)

"""#### **Sub Task3: Correct the years in the given data set**



**The idea behind this is: The start day of every year is 'YYYY-01-01' and we have the 2022 for the entire dataset. As soon as we reach the row where date is equal to '2022-01-01', the year will be updated untill we reach the row where the date is again '2022-01-01'.**



PS: *This might not be optimal way of doing this. But looking at the dataset and format of date column. The values of the date column are in order*
"""

# Keeping a note of the index where we have the date '2022-01-01'
index_array = (df[df['date']=='2022-01-01'].index.values.astype(int))

year = 2022  # setting the value of the year
new_year = 2022 #setting the value of the year to be updated
for i in range(len(index_array)):
  if (index_array[i]==  index_array[-1]):
    df.loc[index_array[i]: , 'date'] = df.date.mask(df.date.dt.year == 2022, df.date + pd.offsets.DateOffset(year = new_year))
  else:
    
    df.loc[index_array[i]:index_array[i+1]-1, 'date'] = df.date.mask(df.date.dt.year == 2022, df.date + pd.offsets.DateOffset(year = new_year))
  year += 1
  new_year = year

#Getting the count of unique values in the date column, which should be total number of rows. 
#Also, getting the start date and the end date of the date column
print(df['date'].nunique())
print(df['date'].max())
print(df['date'].min())

"""**`Year modified` has total 3900 values with starting date as 2022-01-01 till end date as 2033-07-28**

*Hence the years has been modified in the given dataset*

#### **Subtask 4: Checking/Removal of duplicated rows**
"""

df[df.duplicated()]

"""*No more duplicates in the dataset*

**Will drop all these null values if any**
"""

print(df.isnull().sum())

df.dropna(inplace = True)

df.info()

"""#### **Final Comments**

1. All the labels in the dataset have been fixed
2. The data types of all the columns have been changed
3. Duplicate columns/rows have been fixed
4. Date column in the dataset has been fixed by chnaging into appropriate year.

**Saving the cleaned dataset**
"""

df.to_csv('weather_data_cleaned.csv', encoding = 'utf-8-sig', index = None)

files.download('weather_data_cleaned.csv')